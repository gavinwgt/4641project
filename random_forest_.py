# -*- coding: utf-8 -*-
"""Random_Forest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tmVnrcx4Z4ObtRJHNKT9dSgnyv5K0edu
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn import svm
from sklearn.metrics import classification_report
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
from sklearn.ensemble import RandomForestClassifier

# Load the data
df = pd.read_csv("rand_lyrics_with_sentiment.csv")

# Function to extract sentiment value
def extract_value(dict_str, key):
    parts = dict_str.split(",")
    for part in parts:
        if key in part:
            key, value = part.split(":")
            value = value.strip().strip(' {}')
            return float(value)
    return None

# Extract sentiment scores
for column in ['neg', 'neu', 'pos', 'comp']:
    df[column] = df['negnueposcomp'].apply(lambda s: extract_value(s, column))

# Define sentiment based on 'comp'
def label_sentiment(row):
    if row['comp'] > 0:
        return 1
    elif row['comp'] < 0:
        return -1
    else:
        return 0

df['sentiment'] = df.apply(lambda row: label_sentiment(row), axis=1)

# Vectorize lyrics using TF-IDF
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(df['Lyric'])

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, df['sentiment'], test_size=0.2, random_state=42)

# Initialize the Random Forest Classifier
rf_clf = RandomForestClassifier(n_estimators=200, random_state=10)

# Fit the data to the model
rf_clf.fit(X_train, y_train)

# Predict the labels of the test set
y_pred_rf = rf_clf.predict(X_test)

# Print the classification report
print(classification_report(y_test, y_pred_rf))

# Generate the confusion matrix
cm_rf = confusion_matrix(y_test, y_pred_rf)

# Create a DataFrame from the confusion matrix
cm_rf_df = pd.DataFrame(cm_rf, index=['Negative', 'Neutral', 'Positive'], columns=['Negative', 'Neutral', 'Positive'])

# Plot the confusion matrix as a heatmap
plt.figure(figsize=(10, 7))
sns.heatmap(cm_rf_df, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix for Random Forest')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# Calculate feature importances
importances = rf_clf.feature_importances_

# Create a DataFrame for visualization
feature_importances = pd.DataFrame({"feature": vectorizer.get_feature_names_out(), "importance": importances})

# Sort by importance
feature_importances = feature_importances.sort_values("importance", ascending=False)

# Plot the top 20 features
plt.figure(figsize=(10,6))
sns.barplot(x="importance", y="feature", data=feature_importances.head(20))
plt.title("Feature Importances")
plt.show()